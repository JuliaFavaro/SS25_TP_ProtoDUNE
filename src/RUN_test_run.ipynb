{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d726aa",
   "metadata": {},
   "source": [
    "# Parameter evaluation of clustering method for Real Data from the PDHD Detector\n",
    "## **This notebook focuses on the run 32974, collection plane, APA2 (TPC3).**\n",
    "\n",
    "In RUN_test_event_run.ipynb we analyzed the possibility of using a sequential clustering and then linear regression pattern finding inside the clusters. In this notebook we want to identify if there is a viable solution to find the optimal hyperparameters for these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581fcd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot #Uproot is a Python library that allows you to read, write, and manipulate ROOT files without requiring ROOT or C++.\n",
    "import awkward as ak #this is for ragged data handling, which is common in particle physics data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "# %matplotlib widget \n",
    "warnings.filterwarnings('ignore') # Ignore warnings for cleaner output\n",
    "\n",
    "filepath = \"../data/pdhd_run032974_tps.root\"    \n",
    "\n",
    "with uproot.open(filepath) as file:\n",
    "    tree = file[\"triggerana/tree\"]  # Adjust the path if your tree is elsewhere\n",
    "    print(tree.keys())  # This prints all branch names in the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of using all the branches, we can specify which ones we want to read\n",
    "def load_data(filepath, branch_names, max_events=3000):\n",
    "    \"\"\"Load data from a ROOT file into a pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        with uproot.open(filepath) as file:\n",
    "            tree = file[\"triggerana/tree\"]\n",
    "            arrays = tree.arrays(branch_names, library=\"ak\", entry_stop=max_events)\n",
    "            return ak.to_dataframe(arrays)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "# name of branches in the TTree to read into the pandas df\n",
    "TP_BRANCHES_df = ['event', 'run', 'subrun', 'TP_channel', 'TP_startT', 'TP_peakT', 'TP_TOT', 'TP_SADC', 'TP_peakADC', 'TP_plane', 'TP_TPC'] #trigger primitives for real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be76ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's load the data from runs\n",
    "df_32974= load_data(filepath, TP_BRANCHES_df, 10000)\n",
    "df_32974.run_name = \"Cosmic run 32974\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bdba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this notebook we will try to do some more statystics and use all of them\n",
    "events = df_32974.event.unique()\n",
    "print(f\"Event {events}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d9cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable for APA ranges\n",
    "apa_ranges = {\n",
    "    \"APA1\": (0, 2560),\n",
    "    \"APA3\": (2560, 5120),\n",
    "    \"APA2\": (5120, 7680),\n",
    "    \"APA4\": (7680, 10240),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7110b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plane=2\n",
    "\n",
    "def make_title(run, event, cuts=\"no cuts\"):\n",
    "    return f\"Run {run} | Event {event} | Plane {plane} | {cuts}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b062241",
   "metadata": {},
   "source": [
    "### Characteristics of a single run (collection plane) hits of a single TPC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da67002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestamps correspond to microseconds, the big number is the first detection hit in timestamp\n",
    "# Note: APA1 collection plane is broken so we will not use it in this analysis.\n",
    "\n",
    "tps_32974 = df_32974\n",
    "tps_32974.run_name = \"Cosmic run 32974\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee33beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = 1, (tps_32974[\"TP_SADC\"].max()/1e3)/2\n",
    "plt.figure()\n",
    "\n",
    "tps = tps_32974[tps_32974.TP_plane == plane]\n",
    "tps.run_name = \"Cosmic run 32974\"\n",
    "sc = plt.scatter(tps.TP_peakT, tps.TP_channel, s=tps.TP_TOT / 10, c=tps.TP_SADC/1e3, cmap='gist_rainbow', vmin=vmin, vmax=vmax)\n",
    "plt.xlabel(\"timestamp\")\n",
    "plt.ylabel(\"channel\")\n",
    "\n",
    "plt.suptitle(make_title(tps['run'].unique()[0], plane))\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label(\"SADC [kADC * tick]\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3376d783",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"TP_SADC: Minimum value {tps['TP_SADC'].min()/1e3}, maximum {(tps['TP_SADC'].max()/1e3)}, mean {tps['TP_SADC'].mean()/1e3}, std deviation {tps['TP_SADC'].std()/1e3}\")\n",
    "print(f\"TP_PeakADC: Minimum value {tps['TP_peakADC'].min()}, maximum {(tps['TP_peakADC'].max())}, mean {tps['TP_peakADC'].mean()}, std deviation {tps['TP_peakADC'].std()}\")\n",
    "print(f\"TP_TOT: Minimum value {tps['TP_TOT'].min()}, maximum {(tps['TP_TOT'].max())}, mean {tps['TP_TOT'].mean()}, std deviation {tps['TP_TOT'].std()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0b76a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(16, 9), gridspec_kw={'height_ratios': [1, 2]})\n",
    "\n",
    "plt.suptitle(make_title(tps['run'].unique()[0], plane))\n",
    "\n",
    "# 1. TP_SADC\n",
    "bins_sadc = np.linspace(tps['TP_SADC'].min()/1e3, tps['TP_SADC'].max()/2e3, 100)\n",
    "axs[0, 0].hist(tps['TP_SADC']/1e3, bins=bins_sadc, alpha=0.8, color='salmon')\n",
    "axs[0, 0].set_xlabel('TP_SADC [kADC * tick]')\n",
    "axs[0, 0].set_ylabel('Counts')\n",
    "axs[0, 0].set_xlim(bins_sadc[0], bins_sadc[-1])\n",
    "\n",
    "mask_sadc = (tps['TP_SADC']/1e3 >= 0) & (tps['TP_SADC']/1e3 <= 15)\n",
    "tps_zoom_sadc = tps[mask_sadc]\n",
    "bins_sadc_zoom = np.linspace(0, 15, 100)\n",
    "axs[1, 0].hist(tps_zoom_sadc['TP_SADC']/1e3, bins=bins_sadc_zoom, alpha=0.8, color='salmon')\n",
    "axs[1, 0].set_xlabel('TP_SADC [kADC * tick]')\n",
    "axs[1, 0].set_ylabel('Counts')\n",
    "axs[1, 0].set_xlim(bins_sadc_zoom[0], bins_sadc_zoom[-1])\n",
    "\n",
    "threshold_sadc = 1.5\n",
    "sadc_cut = tps_zoom_sadc[tps_zoom_sadc['TP_SADC']/1e3 > threshold_sadc]\n",
    "axs[1, 0].hist(sadc_cut['TP_SADC']/1e3, bins=bins_sadc_zoom, histtype='step', color='gray', linewidth=2, label='SADC > 1.5')\n",
    "axs[1, 0].legend()\n",
    "\n",
    "# 2. TP_peakADC\n",
    "bins_adc = np.linspace(tps['TP_peakADC'].min(), tps['TP_peakADC'].max()/2, 100)\n",
    "axs[0, 1].hist(tps['TP_peakADC'], bins=bins_adc, alpha=0.8, color='skyblue')\n",
    "axs[0, 1].set_xlabel('TP_peakADC [ADC]')\n",
    "axs[0, 1].set_ylabel('Counts')\n",
    "axs[0, 1].set_xlim(bins_adc[0], bins_adc[-1])\n",
    "\n",
    "mask_adc = (tps['TP_peakADC'] >= 61) & (tps['TP_peakADC'] <= 1000)\n",
    "tps_zoom_adc = tps[mask_adc]\n",
    "bins_adc_zoom = np.linspace(61, 1000, 100)\n",
    "axs[1, 1].hist(tps_zoom_adc['TP_peakADC'], bins=bins_adc_zoom, alpha=0.8, color='skyblue')\n",
    "axs[1, 1].set_xlabel('TP_peakADC')\n",
    "axs[1, 1].set_ylabel('Counts')\n",
    "axs[1, 1].set_xlim(bins_adc_zoom[0], bins_adc_zoom[-1])\n",
    "\n",
    "threshold_adc = 180\n",
    "adc_cut = tps_zoom_adc[tps_zoom_adc['TP_peakADC'] > threshold_adc]\n",
    "axs[1, 1].hist(adc_cut['TP_peakADC'], bins=bins_adc_zoom, histtype='step', color='gray', linewidth=2, label='ADC > 180')\n",
    "axs[1, 1].legend()\n",
    "\n",
    "# 3. TP_TOT\n",
    "bins_tot = np.linspace(tps['TP_TOT'].min(), tps['TP_TOT'].max()/2, 100)\n",
    "axs[0, 2].hist(tps['TP_TOT'], bins=bins_tot, alpha=0.8, color='mediumseagreen')\n",
    "axs[0, 2].set_xlabel('TP_TOT')\n",
    "axs[0, 2].set_ylabel('Counts')\n",
    "axs[0, 2].set_xlim(bins_tot[0], bins_tot[-1])\n",
    "\n",
    "mask_tot = (tps['TP_TOT'] >= 1) & (tps['TP_TOT'] <= 100)\n",
    "tps_zoom_tot = tps[mask_tot]\n",
    "bins_tot_zoom = np.linspace(1, 100, 100)\n",
    "axs[1, 2].hist(tps_zoom_tot['TP_TOT'], bins=bins_tot_zoom, alpha=0.8, color='mediumseagreen')\n",
    "axs[1, 2].set_xlabel('TP_TOT')\n",
    "axs[1, 2].set_ylabel('Counts')\n",
    "axs[1, 2].set_xlim(bins_tot_zoom[0], bins_tot_zoom[-1])\n",
    "\n",
    "threshold_tot = 8\n",
    "tot_cut = tps_zoom_tot[tps_zoom_tot['TP_TOT'] > threshold_tot]\n",
    "axs[1, 2].hist(tot_cut['TP_TOT'], bins=bins_tot_zoom, histtype='step', color='gray', linewidth=2, label='TOT > 8')\n",
    "axs[1, 2].legend()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f84bae",
   "metadata": {},
   "source": [
    "- The small bump is connected to the actual presence of MIP\n",
    "\n",
    "- The noise we are seeing i the small contribution of natural radioactivity of Liquid Argon 39\n",
    "\n",
    "    Apparently the same cuts we used for one single event work in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a98a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store intra-event intervals and inter-event gaps\n",
    "intra_event_diffs = []\n",
    "event_firsts = []\n",
    "event_lasts = []\n",
    "event_durations_seconds = []\n",
    "\n",
    "for ev in events:\n",
    "    ev_df = tps[tps.event == ev]\n",
    "    ts = np.sort(ev_df[\"TP_peakT\"].unique())\n",
    "    if len(ts) > 1:\n",
    "        intra_event_diffs.append(np.diff(ts))\n",
    "        duration_ticks = ts.max() - ts.min()\n",
    "        duration_seconds = duration_ticks * 500 / 1e9 #each tick corresponds to 500 ns\n",
    "        event_durations_seconds.append(duration_seconds)\n",
    "    event_firsts.append(ts[0])\n",
    "    event_lasts.append(ts[-1])\n",
    "\n",
    "# Flatten intra-event diffs for global histogram\n",
    "intra_event_flat = np.concatenate(intra_event_diffs)\n",
    "\n",
    "# Compute inter-event gaps\n",
    "event_firsts = np.array(event_firsts)\n",
    "event_lasts = np.array(event_lasts)\n",
    "inter_event_gaps = event_firsts[1:] - event_lasts[:-1]\n",
    "inter_event_gaps_seconds = inter_event_gaps * 500 / 1e9\n",
    "\n",
    "print(f\"Event duration: {np.mean(intra_event_flat):.4f} s\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 8))\n",
    "axs[0].hist(intra_event_flat, bins=int(2*np.sqrt(len(intra_event_flat))), color='salmon', alpha=0.8, log=True) #y axis in log scale\n",
    "axs[0].set_title('Distribution of time intervals within each event')\n",
    "axs[0].set_xlabel('Time difference between consecutive timestamps (ticks)')\n",
    "axs[0].set_ylabel('Counts')\n",
    "axs[0].set_xlim(0, 10)\n",
    "\n",
    "# Bar plot with custom labels for event pairs\n",
    "axs[1].bar(range(len(inter_event_gaps_seconds)), inter_event_gaps_seconds, color='skyblue', alpha=0.8)\n",
    "axs[1].set_title('Time gap between end of event N and start of event N+1')\n",
    "axs[1].set_xlabel('Event pair')\n",
    "axs[1].set_ylabel('Gap [s]')\n",
    "axs[1].set_xticks(range(len(events)))\n",
    "axs[1].set_xticklabels(events, rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26b9204",
   "metadata": {},
   "source": [
    "### Looking into thresholds and noise removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad335f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_TPC_activity(tp_df, thresh, thresh_type=\"TP_peakADC\", vmin=None, vmax=None, show_counts=True):  \n",
    "    \"\"\"\n",
    "    Creates scatter plots showing TP distribution across APAs with optional bar charts for TP counts. \n",
    "    Scatter plot point sizes are proportional to TP_TOT/10. Scatter plot colors represent TP_SADC values using 'gist_rainbow' colormap\n",
    "    Data is filtered based on specified threshold criteria to remove noise.\n",
    "    Creates 2x2 subplot grid for the 4 APAs in ProtoDUNE. Requires global variable 'apa_ranges' containing APA channel ranges\n",
    "\n",
    "    ----------\n",
    "    tp_df : pandas.DataFrame\n",
    "        DataFrame containing trigger primitive data\n",
    "        \n",
    "    thresh : float\n",
    "        Threshold value for filtering TPs. \n",
    "        \n",
    "    thresh_type : str, optional\n",
    "        Type of threshold to apply for filtering. Default is \"TP_peakADC\".\n",
    "        Options:\n",
    "        - \"TP_peakADC\": Filter by peak ADC value\n",
    "        - \"TP_TOT\": Filter by time over threshold\n",
    "        - \"TP_SADC\": Filter by sum ADC (divided by 1e3 for kADC units)\n",
    "        \n",
    "    vmin : float, optional\n",
    "        Minimum value for colorbar scale in scatter plots. If None, uses data minimum.\n",
    "        \n",
    "    vmax : float, optional\n",
    "        Maximum value for colorbar scale in scatter plots. If None, uses data maximum.\n",
    "        \n",
    "    show_counts : bool, optional\n",
    "        Whether to display bar chart showing TP counts per APA. Default is True.\n",
    "    \"\"\"\n",
    "    global apa_ranges \n",
    "    title_prefix = \"TP Activity per APA\"\n",
    "    # Filter based on the threshold type\n",
    "    if thresh_type == \"TP_peakADC\":\n",
    "        filtered = tp_df[tp_df.TP_peakADC > thresh]\n",
    "    elif thresh_type == \"TP_TOT\":\n",
    "        filtered = tp_df[tp_df.TP_TOT > thresh]\n",
    "    elif thresh_type == \"TP_SADC\":\n",
    "        filtered = tp_df[tp_df.TP_SADC / 1e3 > thresh]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown threshold type: {thresh_type}\")\n",
    "\n",
    "    print(f\"Threshold ({thresh_type}): {thresh} (TPs: {len(filtered)}, Retaining {len(filtered)/len(tp_df)*100:.2f}% of raw TP)\")\n",
    "    run_type = tp_df.run_name if hasattr(tp_df, 'run_name') else \"unknown_run\"\n",
    "    plot_title = f\"{title_prefix} ({run_type}, threshold: {thresh_type} > {thresh})\"\n",
    "\n",
    "    # --- Scatter plots ---\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 10), sharex=True)\n",
    "    for i, (apa, (start, stop)) in enumerate(apa_ranges.items()):\n",
    "        ax = axs[i//2][i%2]\n",
    "        df_apa = filtered[(filtered.TP_channel >= start) & (filtered.TP_channel < stop)]\n",
    "        sc = ax.scatter(\n",
    "            df_apa.TP_peakT, df_apa.TP_channel,\n",
    "            s=df_apa.TP_TOT / 10,\n",
    "            c=df_apa.TP_SADC,\n",
    "            cmap=\"gist_rainbow\",\n",
    "            alpha=0.7,\n",
    "            edgecolor=\"none\",\n",
    "            vmin=vmin, vmax=vmax\n",
    "        )\n",
    "        ax.set_title(f\"{apa} (channels {start}-{stop-1})\")\n",
    "        ax.set_xlabel(\"timestamp\")\n",
    "        ax.set_ylabel(\"TP_channel\")\n",
    "        ax.grid(True, linestyle=\"dotted\", alpha=0.5)\n",
    "\n",
    "    plt.suptitle(f\"{plot_title}\", fontsize=18)\n",
    "    fig.colorbar(sc, ax=axs, orientation=\"vertical\", shrink=0.8, label=\"TP SADC\")\n",
    "    plt.show()\n",
    "\n",
    "    # --- Bar plot: TP count per APA ---\n",
    "    if show_counts:\n",
    "        apa_counts = [\n",
    "            len(filtered[(filtered.TP_channel >= start) & (filtered.TP_channel < stop)])\n",
    "            for (start, stop) in apa_ranges.values()\n",
    "        ]\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.bar(apa_ranges.keys(), apa_counts, color='steelblue')\n",
    "        plt.ylabel(\"Number of TPs\")\n",
    "        plt.title(f\"Total TP Count per APA ({thresh_type} > {thresh})\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066864b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (tps['event'] < 25)\n",
    "tps_subset = tps[mask]\n",
    "tps_subset.run_name = tps.run_name\n",
    "\n",
    "# For SADC threshold\n",
    "plot_TPC_activity(tps_subset, threshold_sadc, \n",
    "            vmin=2000, vmax=25000, thresh_type=\"TP_SADC\", show_counts=False)\n",
    "\n",
    "# For ADC threshold\n",
    "plot_TPC_activity(tps_subset, threshold_adc, \n",
    "            vmin=2000, vmax=25000, thresh_type=\"TP_peakADC\", show_counts=False)\n",
    "\n",
    "# For TOT threshold\n",
    "plot_TPC_activity(tps_subset, threshold_tot, \n",
    "            vmin=2000, vmax=25000, thresh_type=\"TP_TOT\", show_counts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e7d8f1",
   "metadata": {},
   "source": [
    "- Big dots are just particles perpedincular to one single channel and therefore releasing a lot of energy in that single channel.\n",
    "- Because the peakT are so different it's impossible to see any tracks inside the events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca19d65",
   "metadata": {},
   "source": [
    "### Spatial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daaaece",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tps= tps_subset[tps_subset.TP_SADC / 1e3 > threshold_sadc]\n",
    "filtered_APA2=filtered_tps[(filtered_tps.TP_channel>=apa_ranges[\"APA2\"][0]) & (filtered_tps.TP_channel<apa_ranges[\"APA2\"][1])]\n",
    "filtered_APA2.run_name = tps.run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cb236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Event-by-Event TP_TOT Distribution Analysis for APA3\n",
    "\n",
    "This cell performs a detailed statistical analysis of Time Over Threshold (TP_TOT) distributions across multiple cosmic ray events in APA3.\n",
    "\n",
    "Analysis Strategy:\n",
    "-----------------\n",
    "Instead of combining all TP_TOT values from multiple events into a single histogram (which can\n",
    "smooth out important features), this analysis:\n",
    "\n",
    "1. Calculates individual normalized histograms for each event\n",
    "2. Computes the average normalized distribution across all events\n",
    "3. Creates a 2D heatmap showing TP_TOT distributions per event\n",
    "\n",
    "Motivation:\n",
    "---------------------\n",
    "- Different cosmic ray events may be dominated by different track types or signal populations: aggregating all TP_TOT values can lead to merging and overlapping peaks, \n",
    "resulting in a smoother distribution that obscures distinct features.\n",
    "- This approach wants to reveal common structural features across events\n",
    "\n",
    "Binning: 200 bins from 0 to 100 TP_TOT units for high resolution\n",
    "\"\"\"\n",
    "\n",
    "events = np.sort(filtered_APA2['event'].unique())\n",
    "bins = np.linspace(0, 100, 100)  # 200 bin da 0 a 100\n",
    "#: in alcuni eventi possono dominare certe tracce o tipologie di segnali che producono un picco, in altri eventi un’altra popolazione. \n",
    "# Sommando tutto, i picchi possono “mescolarsi” e sovrapporsi, risultando in una distribuzione più smooth e larga senza due massimi evidenti.\n",
    "\n",
    "# ================= TP_TOT =================\n",
    "# Invece di sommare tutte le TP_TOT di 88 eventi insieme, calcola la distribuzione per ogni evento e poi somma (“stacked histogram”) o fai la media delle distribuzioni normalizzate.\n",
    "# Questo evita che eventi molto “ricchi” dominino la statistica, e fa emergere strutture comuni.\n",
    "all_event_histos_tot = []\n",
    "for ev in events:\n",
    "    dat = filtered_APA2[filtered_APA2['event'] == ev]['TP_TOT']\n",
    "    counts, _ = np.histogram(dat, bins=bins)\n",
    "    if counts.sum() > 0:\n",
    "        counts = counts / counts.sum()\n",
    "    all_event_histos_tot.append(counts)\n",
    "mean_histo_tot = np.mean(all_event_histos_tot, axis=0)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar((bins[:-1]+bins[1:])/2, mean_histo_tot, width=np.diff(bins), color='darkseagreen', alpha=0.8)\n",
    "plt.xlabel(\"TP_TOT\")\n",
    "plt.ylabel(\"Normalized avg counts (per event)\")\n",
    "plt.title(f\"Stacked TP_TOT per event distributions. \\n{len(events)} events, 200 bin, APA3, TP_SADC > {threshold_sadc})\")\n",
    "plt.xlim(0, 100)\n",
    "plt.grid(True, linestyle=\"dotted\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a307d2",
   "metadata": {},
   "source": [
    "Most of the events seem to be between 11-18, the bimodial distribution that is clear in the case of **RUN_test_event_run.ipynb** is not visibile over here."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6485f93",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "\n",
    "events = np.unique(filtered_APA2['event'])\n",
    "\n",
    "# Define parameter grid\n",
    "eps_grid = np.arange(5, 100, 25)         # Example: from 5 to 95 in steps of 5\n",
    "min_samples_grid = np.arange(2, 20, 1)   # Example: from 2 to 7\n",
    "\n",
    "results = []\n",
    "\n",
    "for ev in events:\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    # Optional: normalize TP_peakT for each event\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min()\n",
    "    X = sel[['TP_peakT', 'TP_channel']].values\n",
    "\n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_n_clusters = None\n",
    "\n",
    "    for eps in eps_grid:\n",
    "        for min_samples in min_samples_grid:\n",
    "            db = DBSCAN(eps=eps, min_samples=min_samples).fit(X)\n",
    "            labels = db.labels_\n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            # Silhouette is defined only if there are at least 2 clusters (excluding noise)\n",
    "            if n_clusters > 1:\n",
    "                try:\n",
    "                    score = metrics.silhouette_score(X, labels)\n",
    "                except Exception:\n",
    "                    score = -1\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = (eps, min_samples)\n",
    "                    best_n_clusters = n_clusters\n",
    "    results.append({\n",
    "        \"event\": ev,\n",
    "        \"best_eps\": best_params[0] if best_params else None,\n",
    "        \"best_min_samples\": best_params[1] if best_params else None,\n",
    "        \"best_score\": best_score if best_score > -1 else None,\n",
    "        \"n_clusters\": best_n_clusters if best_n_clusters else None,\n",
    "    })\n",
    "\n",
    "# Show full summary table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary table of best DBSCAN hyperparameters per event:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f52d255",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "events = np.unique(filtered_APA2['event'])\n",
    "print(\"Are events unique?\", len(events) == len(set(events)))\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(16, 10), sharex=True, gridspec_kw={'height_ratios': [1,2]})\n",
    "\n",
    "# Variabili per offset e limiti\n",
    "offset = 0\n",
    "ymin = filtered_APA2['TP_channel'].min()\n",
    "ymax = filtered_APA2['TP_channel'].max()\n",
    "colors = plt.cm.tab10.colors\n",
    "\n",
    "# --- SUBPLOT SOPRA: solo punti senza clustering ---\n",
    "offset = 0\n",
    "for i, ev in enumerate(events):\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min() + offset\n",
    "    tmin = sel['TP_peakT'].min()\n",
    "    tmax = sel['TP_peakT'].max()\n",
    "    axs[0].scatter(sel['TP_peakT'], sel['TP_channel'], s=10, alpha=0.7, color=colors[i % 10], label=f'Event {ev}')\n",
    "    \n",
    "    # Rettangolo evento\n",
    "    rect = Rectangle((tmin, ymin), tmax-tmin, ymax-ymin, linewidth=2, edgecolor=colors[i % 10], facecolor='none', linestyle='--')\n",
    "    axs[0].add_patch(rect)\n",
    "    offset += tmax - tmin + 1000\n",
    "\n",
    "axs[0].set_ylabel('TP_channel')\n",
    "axs[0].set_title('(TP_peakT, TP_channel) per event')\n",
    "\n",
    "# --- SUBPLOT SOTTO: clustering e rettangoli ---\n",
    "offset = 0\n",
    "for i, ev in enumerate(events):\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy() # single event selection\n",
    "\n",
    "    #this is to normalize the TP_peakT values for better visualization\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min() + offset\n",
    "    tmin = sel['TP_peakT'].min()\n",
    "    tmax = sel['TP_peakT'].max()\n",
    "\n",
    "    # Clustering\n",
    "    X = sel[['TP_peakT', 'TP_channel']].values\n",
    "    db = DBSCAN(eps=80, min_samples=15).fit(X)\n",
    "    sel['cluster'] = db.labels_\n",
    "    labels = sel['cluster']\n",
    "\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    if n_clusters > 1:\n",
    "        print(f'Silhouette (event {ev}): {metrics.silhouette_score(X, labels)}')\n",
    "    else:\n",
    "        print(f'Silhouette (event {ev}): N/A (only one cluster or all noise)')\n",
    "\n",
    "    # Punti per cluster\n",
    "    for c in np.unique(sel['cluster']):\n",
    "        if c == -1: continue\n",
    "        sub = sel[sel['cluster'] == c]\n",
    "        axs[1].scatter(sub['TP_peakT'], sub['TP_channel'], s=10, alpha=0.8, color=colors[c % 10])\n",
    "\n",
    "    # this rectangle makes the visualization easier\n",
    "    rect = Rectangle((tmin, ymin), tmax-tmin, ymax-ymin, linewidth=2, edgecolor=colors[i % 10], facecolor='none', linestyle='--')\n",
    "    axs[1].add_patch(rect)\n",
    "    axs[1].text(tmin + (tmax-tmin)*0.01, ymax+30, f'Event {ev}', fontsize=10, color=colors[i % 10], va='top')\n",
    "    offset += tmax - tmin + 1000\n",
    "\n",
    "axs[1].set_xlabel('TP_peakT (normalized)')\n",
    "axs[1].set_ylabel('TP_channel')\n",
    "axs[1].set_title('Clustering DBSCAN')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c99ff499",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.linear_model import RANSACRegressor, LinearRegression\n",
    "from sklearn import metrics\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "events = np.unique(filtered_APA2['event'])\n",
    "print(\"Are events unique?\", len(events) == len(set(events)))\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(16, 14), sharex=True, gridspec_kw={'height_ratios': [1,1,2]})\n",
    "\n",
    "offset = 0\n",
    "ymin = filtered_APA2['TP_channel'].min()\n",
    "ymax = filtered_APA2['TP_channel'].max()\n",
    "colors = plt.cm.tab10.colors\n",
    "\n",
    "# --- SUBPLOT 1: Only raw points, no clustering ---\n",
    "offset = 0\n",
    "for i, ev in enumerate(events):\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min() + offset\n",
    "    tmin = sel['TP_peakT'].min()\n",
    "    tmax = sel['TP_peakT'].max()\n",
    "    axs[0].scatter(sel['TP_peakT'], sel['TP_channel'], s=10, alpha=0.7, color=colors[i % 10], label=f'Event {ev}')\n",
    "    rect = Rectangle((tmin, ymin), tmax-tmin, ymax-ymin, linewidth=2, edgecolor=colors[i % 10], facecolor='none', linestyle='--')\n",
    "    axs[0].add_patch(rect)\n",
    "    offset += tmax - tmin + 1000\n",
    "axs[0].set_ylabel('TP_channel')\n",
    "axs[0].set_title('(TP_peakT, TP_channel) per event')\n",
    "axs[0].legend(fontsize=9)\n",
    "\n",
    "# --- SUBPLOT 2: Clusters and event boxes ---\n",
    "offset = 0\n",
    "for i, ev in enumerate(events):\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min() + offset\n",
    "    tmin = sel['TP_peakT'].min()\n",
    "    tmax = sel['TP_peakT'].max()\n",
    "    X = sel[['TP_peakT', 'TP_channel']].values\n",
    "    db = DBSCAN(eps=80, min_samples=15).fit(X)\n",
    "    sel['cluster'] = db.labels_\n",
    "    labels = sel['cluster']\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    if n_clusters > 1:\n",
    "        print(f'Silhouette (event {ev}): {metrics.silhouette_score(X, labels)}')\n",
    "    else:\n",
    "        print(f'Silhouette (event {ev}): N/A (only one cluster or all noise)')\n",
    "\n",
    "    for c in np.unique(sel['cluster']):\n",
    "        if c == -1: continue\n",
    "        sub = sel[sel['cluster'] == c]\n",
    "        axs[1].scatter(sub['TP_peakT'], sub['TP_channel'], s=10, alpha=0.8, color=colors[c % 10])\n",
    "    rect = Rectangle((tmin, ymin), tmax-tmin, ymax-ymin, linewidth=2, edgecolor=colors[i % 10], facecolor='none', linestyle='--')\n",
    "    axs[1].add_patch(rect)\n",
    "    axs[1].text(tmin + (tmax-tmin)*0.01, ymax+30, f'Event {ev}', fontsize=10, color=colors[i % 10], va='top')\n",
    "    offset += tmax - tmin + 1000\n",
    "axs[1].set_ylabel('TP_channel')\n",
    "axs[1].set_title('Clustering DBSCAN')\n",
    "\n",
    "# --- SUBPLOT 3: Clusters with RANSAC tracks and event boxes ---\n",
    "offset = 0\n",
    "min_points_line = 12         # Minimum inliers for a track, adjust as needed\n",
    "residual_threshold = 5     # RANSAC residual threshold, adjust as needed\n",
    "max_trials = 50\n",
    "\n",
    "for i, ev in enumerate(events):\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min() + offset\n",
    "    tmin = sel['TP_peakT'].min()\n",
    "    tmax = sel['TP_peakT'].max()\n",
    "    X = sel[['TP_peakT', 'TP_channel']].values\n",
    "    db = DBSCAN(eps=80, min_samples=15).fit(X)\n",
    "    sel['cluster'] = db.labels_\n",
    "    \n",
    "    for c in np.unique(sel['cluster']):\n",
    "        if c == -1: continue  # skip noise\n",
    "        sub = sel[sel['cluster'] == c]\n",
    "        pts = sub[['TP_peakT', 'TP_channel']].values\n",
    "        #axs[2].scatter(pts[:,0], pts[:,1], s=10, alpha=0.7, color=colors[c % 10])\n",
    "        # --- RANSAC pattern recognition for multiple tracks per cluster ---\n",
    "        cluster_points = pts.copy()\n",
    "        tracks_found = 0\n",
    "        while len(cluster_points) >= min_points_line:\n",
    "            model = RANSACRegressor(LinearRegression(), residual_threshold=residual_threshold, min_samples=min_points_line,max_trials=max_trials)\n",
    "            model.fit(cluster_points[:,0].reshape(-1,1), cluster_points[:,1])\n",
    "            inlier_mask = model.inlier_mask_\n",
    "            if np.sum(inlier_mask) < min_points_line:\n",
    "                break\n",
    "            # Plot only on the inlier range\n",
    "            x_in = cluster_points[:,0][inlier_mask]\n",
    "            x_fit = np.linspace(x_in.min(), x_in.max(), 100)\n",
    "            y_fit = model.predict(x_fit.reshape(-1,1))\n",
    "            axs[2].plot(x_fit, y_fit, '-', color=colors[c % 10], linewidth=2)\n",
    "            tracks_found += 1\n",
    "            # Remove inliers and continue\n",
    "            cluster_points = cluster_points[~inlier_mask]\n",
    "    rect = Rectangle((tmin, ymin), tmax-tmin, ymax-ymin, linewidth=2, edgecolor=colors[i % 10], facecolor='none', linestyle='--')\n",
    "    axs[2].add_patch(rect)\n",
    "    axs[2].text(tmin + (tmax-tmin)*0.01, ymax+30, f'Event {ev}', fontsize=10, color=colors[i % 10], va='top')\n",
    "    offset += tmax - tmin + 1000\n",
    "\n",
    "axs[2].set_xlabel('TP_peakT (normalized)')\n",
    "axs[2].set_ylabel('TP_channel')\n",
    "axs[2].set_title('Clustering DBSCAN + RANSAC tracks')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1629c530",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Helper function to optimize RANSAC hyperparameters for a set of points\n",
    "def optimize_ransac_hyperparams(X, y, param_grid):\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        try:\n",
    "            model = RANSACRegressor(\n",
    "                LinearRegression(),\n",
    "                residual_threshold=params['residual_threshold'],\n",
    "                min_samples=params['min_points_line'],\n",
    "                max_trials=params['max_trials'],\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X, y)\n",
    "            inlier_mask = model.inlier_mask_\n",
    "            if inlier_mask is None or np.sum(inlier_mask) < params['min_points_line']:\n",
    "                continue\n",
    "            score = model.score(X[inlier_mask], y[inlier_mask])\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = params\n",
    "        except Exception:\n",
    "            continue\n",
    "    return best_params\n",
    "\n",
    "# --- HYPERPARAMETER SEARCH SPACE ---\n",
    "param_grid = {\n",
    "    'residual_threshold': [2, 3, 4, 5, 6, 8, 10, 12, 14, 16, 20],\n",
    "    'min_points_line': [8, 10, 12, 14, 16, 20],\n",
    "    'max_trials': [30, 50, 70, 100, 150, 200]\n",
    "}\n",
    "\n",
    "# Gather best hyperparameters for each cluster\n",
    "cluster_best_params = []\n",
    "for i, ev in enumerate(events):\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min()\n",
    "    X = sel[['TP_peakT', 'TP_channel']].values\n",
    "    db = DBSCAN(eps=80, min_samples=15).fit(X)\n",
    "    sel['cluster'] = db.labels_\n",
    "    for c in np.unique(sel['cluster']):\n",
    "        if c == -1: continue  # skip noise\n",
    "        sub = sel[sel['cluster'] == c]\n",
    "        pts = sub[['TP_peakT', 'TP_channel']].values\n",
    "        if len(pts) < min(param_grid['min_points_line']):\n",
    "            continue\n",
    "        X_pts = pts[:,0].reshape(-1,1)\n",
    "        y_pts = pts[:,1]\n",
    "        best_params = optimize_ransac_hyperparams(X_pts, y_pts, param_grid)\n",
    "        if best_params is not None:\n",
    "            cluster_best_params.append(best_params)\n",
    "\n",
    "# Compute average best hyperparameters for events\n",
    "if cluster_best_params:\n",
    "    avg_residual = np.mean([p['residual_threshold'] for p in cluster_best_params])\n",
    "    avg_min_points = int(np.round(np.mean([p['min_points_line'] for p in cluster_best_params])))\n",
    "    avg_max_trials = int(np.round(np.mean([p['max_trials'] for p in cluster_best_params])))\n",
    "else:\n",
    "    # Fallback to defaults if no clusters found\n",
    "    print(f\"No clusters found with sufficient points for RANSAC optimization.\")\n",
    "    avg_residual, avg_min_points, avg_max_trials = 5, 12, 50 #default parameters\n",
    "\n",
    "print(f\"Average best RANSAC hyperparameters: residual_threshold={avg_residual:.2f}, min_points_line={avg_min_points}, max_trials={avg_max_trials}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52b812d7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# --- FINAL PLOTTING ---\n",
    "fig, axs = plt.subplots(3, 1, figsize=(16, 14), sharex=True, gridspec_kw={'height_ratios': [1,1,2]})\n",
    "\n",
    "offset = 0\n",
    "ymin = filtered_APA2['TP_channel'].min()\n",
    "ymax = filtered_APA2['TP_channel'].max()\n",
    "colors = plt.cm.tab10.colors\n",
    "\n",
    "# --- SUBPLOT 1: Only raw points, no clustering ---\n",
    "offset = 0\n",
    "for i, ev in enumerate(events):\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min() + offset\n",
    "    tmin = sel['TP_peakT'].min()\n",
    "    tmax = sel['TP_peakT'].max()\n",
    "    axs[0].scatter(sel['TP_peakT'], sel['TP_channel'], s=10, alpha=0.7, color=colors[i % 10], label=f'Event {ev}')\n",
    "    rect = Rectangle((tmin, ymin), tmax-tmin, ymax-ymin, linewidth=2, edgecolor=colors[i % 10], facecolor='none', linestyle='--')\n",
    "    axs[0].add_patch(rect)\n",
    "    offset += tmax - tmin + 1000\n",
    "axs[0].set_ylabel('TP_channel')\n",
    "axs[0].set_title('(TP_peakT, TP_channel) per event')\n",
    "\n",
    "# --- SUBPLOT 2: Clusters and event boxes ---\n",
    "offset = 0\n",
    "for i, ev in enumerate(events):\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min() + offset\n",
    "    tmin = sel['TP_peakT'].min()\n",
    "    tmax = sel['TP_peakT'].max()\n",
    "    X = sel[['TP_peakT', 'TP_channel']].values\n",
    "    db = DBSCAN(eps=80, min_samples=15).fit(X)\n",
    "    sel['cluster'] = db.labels_\n",
    "    labels = sel['cluster']\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    if n_clusters > 1:\n",
    "        print(f'Silhouette (event {ev}): {metrics.silhouette_score(X, labels)}')\n",
    "    else:\n",
    "        print(f'Silhouette (event {ev}): N/A (only one cluster or all noise)')\n",
    "\n",
    "    for c in np.unique(sel['cluster']):\n",
    "        if c == -1: continue\n",
    "        sub = sel[sel['cluster'] == c]\n",
    "        axs[1].scatter(sub['TP_peakT'], sub['TP_channel'], s=10, alpha=0.8, color=colors[c % 10])\n",
    "    rect = Rectangle((tmin, ymin), tmax-tmin, ymax-ymin, linewidth=2, edgecolor=colors[i % 10], facecolor='none', linestyle='--')\n",
    "    axs[1].add_patch(rect)\n",
    "    offset += tmax - tmin + 1000\n",
    "axs[1].set_ylabel('TP_channel')\n",
    "axs[1].set_title('Clustering DBSCAN')\n",
    "\n",
    "# --- SUBPLOT 3: Clusters with RANSAC tracks and event boxes, using optimized average hyperparameters ---\n",
    "offset = 0\n",
    "for i, ev in enumerate(events):\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min() + offset\n",
    "    tmin = sel['TP_peakT'].min()\n",
    "    tmax = sel['TP_peakT'].max()\n",
    "    X = sel[['TP_peakT', 'TP_channel']].values\n",
    "    db = DBSCAN(eps=80, min_samples=15).fit(X)\n",
    "    sel['cluster'] = db.labels_\n",
    "    \n",
    "    for c in np.unique(sel['cluster']):\n",
    "        if c == -1: continue  # skip noise\n",
    "        sub = sel[sel['cluster'] == c]\n",
    "        pts = sub[['TP_peakT', 'TP_channel']].values\n",
    "        #axs[2].scatter(pts[:,0], pts[:,1], s=10, alpha=0.7, color=colors[c % 10])\n",
    "        # --- RANSAC pattern recognition for multiple tracks per cluster ---\n",
    "        cluster_points = pts.copy()\n",
    "        tracks_found = 0\n",
    "        while len(cluster_points) >= avg_min_points:\n",
    "            model = RANSACRegressor(\n",
    "                LinearRegression(),\n",
    "                residual_threshold=avg_residual,\n",
    "                min_samples=avg_min_points,\n",
    "                max_trials=avg_max_trials,\n",
    "            )\n",
    "            model.fit(cluster_points[:,0].reshape(-1,1), cluster_points[:,1])\n",
    "            inlier_mask = model.inlier_mask_\n",
    "            if inlier_mask is None or np.sum(inlier_mask) < avg_min_points:\n",
    "                break\n",
    "            # Plot only on the inlier range\n",
    "            x_in = cluster_points[:,0][inlier_mask]\n",
    "            x_fit = np.linspace(x_in.min(), x_in.max(), 100)\n",
    "            y_fit = model.predict(x_fit.reshape(-1,1))\n",
    "            axs[2].plot(x_fit, y_fit, '-', color=colors[c % 10], linewidth=2)\n",
    "            tracks_found += 1\n",
    "            # Remove inliers and continue\n",
    "            cluster_points = cluster_points[~inlier_mask]\n",
    "    rect = Rectangle((tmin, ymin), tmax-tmin, ymax-ymin, linewidth=2, edgecolor=colors[i % 10], facecolor='none', linestyle='--')\n",
    "    axs[2].add_patch(rect)\n",
    "    axs[2].text(tmin + (tmax-tmin)*0.01, ymax+30, f'Event {ev}', fontsize=10, color=colors[i % 10], va='top')\n",
    "    offset += tmax - tmin + 1000\n",
    "\n",
    "axs[2].set_xlabel('TP_peakT (normalized)')\n",
    "axs[2].set_ylabel('TP_channel')\n",
    "axs[2].set_title('Clustering DBSCAN + RANSAC tracks (Avg. Optimized Hyperparams)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c82d7659",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# --- HYPERPARAMETER SEARCH SPACE ---\n",
    "param_grid = {\n",
    "    'residual_threshold': [2, 3, 4, 5, 6, 8, 10, 12, 14, 16, 20],\n",
    "    'min_points_line': [8, 10, 12, 14, 16, 20],\n",
    "    'max_trials': [30, 50, 70, 100, 150, 200]\n",
    "}\n",
    "\n",
    "def optimize_ransac_hyperparams(X, y, param_grid):\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        try:\n",
    "            model = RANSACRegressor(\n",
    "                LinearRegression(),\n",
    "                residual_threshold=params['residual_threshold'],\n",
    "                min_samples=params['min_points_line'],\n",
    "                max_trials=params['max_trials'],\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X, y)\n",
    "            inlier_mask = model.inlier_mask_\n",
    "            if inlier_mask is None or np.sum(inlier_mask) < params['min_points_line']:\n",
    "                continue\n",
    "            score = model.score(X[inlier_mask], y[inlier_mask])\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = params\n",
    "        except Exception:\n",
    "            continue\n",
    "    return best_params\n",
    "\n",
    "# --- GATHER OPTIMAL HYPERPARAMS PER CLUSTER AND PER EVENT ---\n",
    "events = np.unique(filtered_APA2['event'])\n",
    "event_cluster_params = {}  # event -> cluster -> params\n",
    "\n",
    "for ev in events:\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min()\n",
    "    X = sel[['TP_peakT', 'TP_channel']].values\n",
    "    db = DBSCAN(eps=80, min_samples=15).fit(X)\n",
    "    sel['cluster'] = db.labels_\n",
    "    event_cluster_params[ev] = {}\n",
    "    for c in np.unique(sel['cluster']):\n",
    "        if c == -1: continue  # skip noise\n",
    "        sub = sel[sel['cluster'] == c]\n",
    "        pts = sub[['TP_peakT', 'TP_channel']].values\n",
    "        if len(pts) < min(param_grid['min_points_line']):\n",
    "            continue\n",
    "        X_pts = pts[:,0].reshape(-1,1)\n",
    "        y_pts = pts[:,1]\n",
    "        best_params = optimize_ransac_hyperparams(X_pts, y_pts, param_grid)\n",
    "        if best_params is not None:\n",
    "            event_cluster_params[ev][c] = best_params"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db4fe0ff",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "# --- FINAL PLOTTING ---\n",
    "fig, axs = plt.subplots(3, 1, figsize=(16, 14), sharex=True, gridspec_kw={'height_ratios': [1,1,2]})\n",
    "\n",
    "offset = 0\n",
    "ymin = filtered_APA2['TP_channel'].min()\n",
    "ymax = filtered_APA2['TP_channel'].max()\n",
    "colors = plt.cm.tab10.colors\n",
    "\n",
    "# --- SUBPLOT 1: Only raw points, no clustering ---\n",
    "offset = 0\n",
    "for i, ev in enumerate(events):\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min() + offset\n",
    "    tmin = sel['TP_peakT'].min()\n",
    "    tmax = sel['TP_peakT'].max()\n",
    "    axs[0].scatter(sel['TP_peakT'], sel['TP_channel'], s=10, alpha=0.7, color=colors[i % 10], label=f'Event {ev}')\n",
    "    rect = Rectangle((tmin, ymin), tmax-tmin, ymax-ymin, linewidth=2, edgecolor=colors[i % 10], facecolor='none', linestyle='--')\n",
    "    axs[0].add_patch(rect)\n",
    "    offset += tmax - tmin + 1000\n",
    "axs[0].set_ylabel('TP_channel')\n",
    "axs[0].set_title('(TP_peakT, TP_channel) per event')\n",
    "axs[0].legend(fontsize=9)\n",
    "\n",
    "# --- SUBPLOT 2: Clusters and event boxes ---\n",
    "offset = 0\n",
    "for i, ev in enumerate(events):\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min() + offset\n",
    "    tmin = sel['TP_peakT'].min()\n",
    "    tmax = sel['TP_peakT'].max()\n",
    "    X = sel[['TP_peakT', 'TP_channel']].values\n",
    "    db = DBSCAN(eps=80, min_samples=15).fit(X)\n",
    "    sel['cluster'] = db.labels_\n",
    "    labels = sel['cluster']\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    if n_clusters > 1:\n",
    "        print(f'Silhouette (event {ev}): {metrics.silhouette_score(X, labels)}')\n",
    "    else:\n",
    "        print(f'Silhouette (event {ev}): N/A (only one cluster or all noise)')\n",
    "\n",
    "    for c in np.unique(sel['cluster']):\n",
    "        if c == -1: continue\n",
    "        sub = sel[sel['cluster'] == c]\n",
    "        axs[1].scatter(sub['TP_peakT'], sub['TP_channel'], s=10, alpha=0.8, color=colors[c % 10])\n",
    "    rect = Rectangle((tmin, ymin), tmax-tmin, ymax-ymin, linewidth=2, edgecolor=colors[i % 10], facecolor='none', linestyle='--')\n",
    "    axs[1].add_patch(rect)\n",
    "    axs[1].text(tmin + (tmax-tmin)*0.01, ymax+30, f'Event {ev}', fontsize=10, color=colors[i % 10], va='top')\n",
    "    offset += tmax - tmin + 1000\n",
    "axs[1].set_ylabel('TP_channel')\n",
    "axs[1].set_title('Clustering DBSCAN')\n",
    "\n",
    "# --- SUBPLOT 3: Clusters with RANSAC tracks and event boxes, using per-cluster hyperparameters ---\n",
    "offset = 0\n",
    "for i, ev in enumerate(events):\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min() + offset\n",
    "    tmin = sel['TP_peakT'].min()\n",
    "    tmax = sel['TP_peakT'].max()\n",
    "    X = sel[['TP_peakT', 'TP_channel']].values\n",
    "    db = DBSCAN(eps=80, min_samples=15).fit(X)\n",
    "    sel['cluster'] = db.labels_\n",
    "    \n",
    "    for c in np.unique(sel['cluster']):\n",
    "        if c == -1: continue  # skip noise\n",
    "        sub = sel[sel['cluster'] == c]\n",
    "        pts = sub[['TP_peakT', 'TP_channel']].values\n",
    "        # Use optimal hyperparams for this event/cluster, else fall back to some safe minimums\n",
    "        params = event_cluster_params.get(ev, {}).get(c, None)\n",
    "        if params is None:\n",
    "            residual_threshold = 5\n",
    "            min_points_line = 12\n",
    "        else:\n",
    "            residual_threshold = params['residual_threshold']\n",
    "            min_points_line = 12\n",
    "        cluster_points = pts.copy()\n",
    "        tracks_found = 0\n",
    "        while len(cluster_points) >= min_points_line:\n",
    "            model = RANSACRegressor(\n",
    "                LinearRegression(),\n",
    "                residual_threshold=residual_threshold,\n",
    "                min_samples=min_points_line,\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(cluster_points[:,0].reshape(-1,1), cluster_points[:,1])\n",
    "            inlier_mask = model.inlier_mask_\n",
    "            if inlier_mask is None or np.sum(inlier_mask) < min_points_line:\n",
    "                break\n",
    "            # Plot only on the inlier range\n",
    "            x_in = cluster_points[:,0][inlier_mask]\n",
    "            x_fit = np.linspace(x_in.min(), x_in.max(), 100)\n",
    "            y_fit = model.predict(x_fit.reshape(-1,1))\n",
    "            axs[2].plot(x_fit, y_fit, '-', color=colors[c % 10], linewidth=2)\n",
    "            tracks_found += 1\n",
    "            # Remove inliers and continue\n",
    "            cluster_points = cluster_points[~inlier_mask]\n",
    "    rect = Rectangle((tmin, ymin), tmax-tmin, ymax-ymin, linewidth=2, edgecolor=colors[i % 10], facecolor='none', linestyle='--')\n",
    "    axs[2].add_patch(rect)\n",
    "    axs[2].text(tmin + (tmax-tmin)*0.01, ymax+30, f'Event {ev}', fontsize=10, color=colors[i % 10], va='top')\n",
    "    offset += tmax - tmin + 1000\n",
    "\n",
    "axs[2].set_xlabel('TP_peakT (normalized)')\n",
    "axs[2].set_ylabel('TP_channel')\n",
    "axs[2].set_title('Clustering DBSCAN + RANSAC tracks (Optimized per-cluster hyperparams)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcdfcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.linear_model import RANSACRegressor, Ridge\n",
    "from sklearn import metrics\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Provided channel_to_z function ---\n",
    "def channel_to_z(channel):\n",
    "    apa_length_in_cm = 230\n",
    "    wire_pitch_in_cm_collection = 0.479\n",
    "    offset_between_apa_in_cm = 2.4\n",
    "\n",
    "    z_apa_offset = (channel // (2560 * 2)) * (apa_length_in_cm + offset_between_apa_in_cm)\n",
    "    z_channel_offset = (((channel % 2560) - 1600) % 480) * wire_pitch_in_cm_collection\n",
    "    z = wire_pitch_in_cm_collection + z_apa_offset + z_channel_offset\n",
    "    return z\n",
    "\n",
    "# --- Your custom distance function ---\n",
    "def channel_distance(ch1, ch2):\n",
    "    return abs(ch1 - ch2)\n",
    "\n",
    "def tp_distance_matrix(points, ticks_limit, channel_limit):\n",
    "    # points: (N, 2) array\n",
    "    tick_diff = np.abs(points[:, None, 0] - points[None, :, 0])\n",
    "    ch_diff = np.abs(points[:, None, 1] - points[None, :, 1])\n",
    "    mask = (tick_diff <= ticks_limit) & (ch_diff <= channel_limit)\n",
    "    norm_dist = np.maximum(tick_diff / ticks_limit, ch_diff / channel_limit)\n",
    "    D = np.where(mask, norm_dist, np.inf)\n",
    "    return D\n",
    "\n",
    "# Example cluster object wrapper for there_is_a_track\n",
    "class ClusterWrapper:\n",
    "    def __init__(self, tps):\n",
    "        self.tps = tps\n",
    "    def get_tps(self):\n",
    "        return self.tps\n",
    "\n",
    "# Example there_is_a_track function (unchanged from user)\n",
    "def there_is_a_track(cluster, z_max, time_mean):\n",
    "    tps = cluster.get_tps()\n",
    "    z = channel_to_z(tps[:,3])\n",
    "    tps = tps[z > z_max]\n",
    "    tps = tps[tps[:,2]*0.08 < time_mean + 15]\n",
    "    tps = tps[tps[:,2]*0.08 > time_mean - 15]\n",
    "    space_left = 460 - z_max\n",
    "    if len(tps) < 0.5*space_left:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "ticks_limit = 3\n",
    "channel_limit = 1\n",
    "min_points_line = 12\n",
    "residual_threshold = 0.5\n",
    "max_trials = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368291c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "events = np.unique(filtered_APA2['event'])\n",
    "fig, axs = plt.subplots(3, 1, figsize=(16, 14), sharex=True, gridspec_kw={'height_ratios': [1,1,2]})\n",
    "offset = 0\n",
    "ymin = filtered_APA2['TP_channel'].min()\n",
    "ymax = filtered_APA2['TP_channel'].max()\n",
    "colors = plt.cm.tab10.colors\n",
    "\n",
    "# --- SUBPLOT 1: raw points ---\n",
    "offset = 0\n",
    "for i, ev in enumerate(events):\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min() + offset\n",
    "    tmin = sel['TP_peakT'].min()\n",
    "    tmax = sel['TP_peakT'].max()\n",
    "    axs[0].scatter(sel['TP_peakT'], sel['TP_channel'], s=10, alpha=0.7, color=colors[i % 10], label=f'Event {ev}')\n",
    "    rect = Rectangle((tmin, ymin), tmax-tmin, ymax-ymin, linewidth=2, edgecolor=colors[i % 10], facecolor='none', linestyle='--')\n",
    "    axs[0].add_patch(rect)\n",
    "    offset += tmax - tmin + 1000\n",
    "axs[0].set_ylabel('TP_channel')\n",
    "axs[0].set_title('(TP_peakT, TP_channel) per event')\n",
    "axs[0].legend(fontsize=9)\n",
    "\n",
    "# --- SUBPLOT 2: Clusters and event boxes ---\n",
    "offset = 0\n",
    "for i, ev in enumerate(events):\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min() + offset\n",
    "    tmin = sel['TP_peakT'].min()\n",
    "    tmax = sel['TP_peakT'].max()\n",
    "    X = sel[['TP_peakT', 'TP_channel']].values\n",
    "    db = DBSCAN(eps=80, min_samples=15).fit(X)\n",
    "    sel['cluster'] = db.labels_\n",
    "    labels = sel['cluster']\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    if n_clusters > 1:\n",
    "        print(f'Silhouette (event {ev}): {metrics.silhouette_score(X, labels)}')\n",
    "    else:\n",
    "        print(f'Silhouette (event {ev}): N/A (only one cluster or all noise)')\n",
    "    for c in np.unique(sel['cluster']):\n",
    "        if c == -1: continue\n",
    "        sub = sel[sel['cluster'] == c]\n",
    "        axs[1].scatter(sub['TP_peakT'], sub['TP_channel'], s=10, alpha=0.8, color=colors[c % 10])\n",
    "    rect = Rectangle((tmin, ymin), tmax-tmin, ymax-ymin, linewidth=2, edgecolor=colors[i % 10], facecolor='none', linestyle='--')\n",
    "    axs[1].add_patch(rect)\n",
    "    axs[1].text(tmin + (tmax-tmin)*0.01, ymax+30, f'Event {ev}', fontsize=10, color=colors[i % 10], va='top')\n",
    "    offset += tmax - tmin + 1000\n",
    "axs[1].set_ylabel('TP_channel')\n",
    "axs[1].set_title('Clustering DBSCAN')\n",
    "\n",
    "# --- SUBPLOT 3: Optimized clusters with RANSAC tracks and event boxes ---\n",
    "offset = 0\n",
    "for i, ev in enumerate(events):\n",
    "    sel = filtered_APA2[filtered_APA2['event'] == ev].copy()\n",
    "    sel['TP_peakT'] = sel['TP_peakT'] - sel['TP_peakT'].min() + offset\n",
    "    tmin = sel['TP_peakT'].min()\n",
    "    tmax = sel['TP_peakT'].max()\n",
    "    X = sel[['TP_peakT', 'TP_channel']].values\n",
    "    db = DBSCAN(eps=80, min_samples=15).fit(X)\n",
    "    sel['cluster'] = db.labels_\n",
    "    for c in np.unique(sel['cluster']):\n",
    "        if c == -1: continue  # skip noise\n",
    "        sub = sel[sel['cluster'] == c]\n",
    "        points = sub[['TP_peakT', 'TP_channel']].values\n",
    "        # --- Skip small clusters: less than or equal to 3 TPs ---\n",
    "        if len(points) <= 3:\n",
    "            continue\n",
    "        #axs[2].scatter(points[:,0], points[:,1], s=10, alpha=0.7, color=colors[c % 10])\n",
    "        # --- Vectorized distance calculation ---\n",
    "        D = tp_distance_matrix(points, ticks_limit, channel_limit)\n",
    "        adjacency = (D < 1.0)\n",
    "        adjacency_sparse = csr_matrix(adjacency)\n",
    "        n_components, labels_cc = connected_components(adjacency_sparse, directed=False)\n",
    "        # --- For each connected component with enough points, fit a track ---\n",
    "        for cc in range(n_components):\n",
    "            comp_pts = points[labels_cc == cc]\n",
    "            if len(comp_pts) < min_points_line:\n",
    "                continue\n",
    "            # If you want to additionally filter with there_is_a_track, do it here:\n",
    "            # The following is a placeholder: you must provide tps with the correct structure!\n",
    "            # Example: tps = np.column_stack((np.zeros(len(comp_pts)), np.zeros(len(comp_pts)), comp_pts[:,0], comp_pts[:,1]))\n",
    "            # cluster_obj = ClusterWrapper(tps)\n",
    "            # z_max = ...; time_mean = ...\n",
    "            # if not there_is_a_track(cluster_obj, z_max, time_mean): continue\n",
    "            X_cc = comp_pts[:,0].reshape(-1,1)\n",
    "            y_cc = comp_pts[:,1]\n",
    "            model = RANSACRegressor(Ridge(alpha=1),\n",
    "                                    residual_threshold=residual_threshold,\n",
    "                                    min_samples=min_points_line,\n",
    "                                    max_trials=max_trials,\n",
    "                                    random_state=0)\n",
    "            model.fit(X_cc, y_cc)\n",
    "            inlier_mask = model.inlier_mask_\n",
    "            if np.sum(inlier_mask) < min_points_line:\n",
    "                continue\n",
    "            x_in = X_cc[inlier_mask][:,0]\n",
    "            x_fit = np.linspace(x_in.min(), x_in.max(), 100)\n",
    "            y_fit = model.predict(x_fit.reshape(-1,1))\n",
    "            axs[2].plot(x_fit, y_fit, '-', color=colors[c % 10], linewidth=2)\n",
    "    rect = Rectangle((tmin, ymin), tmax-tmin, Symax-ymin, linewidth=2, edgecolor=colors[i % 10], facecolor='none', linestyle='--')\n",
    "    axs[2].add_patch(rect)\n",
    "    axs[2].text(tmin + (tmax-tmin)*0.01, ymax+30, f'Event {ev}', fontsize=10, color=colors[i % 10], va='top')\n",
    "    offset += tmax - tmin + 1000\n",
    "\n",
    "axs[2].set_xlabel('TP_peakT (normalized)')\n",
    "axs[2].set_ylabel('TP_channel')\n",
    "axs[2].set_title('DBSCAN + Optimized RANSAC (vectorized, skip small clusters)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30e053a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
